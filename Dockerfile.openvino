# The vLLM Dockerfile is used to construct vLLM image that can be directly used
# to run the OpenAI compatible server.

FROM ubuntu:22.04 AS dev

RUN apt-get update -y && \
    apt-get install -y python3-pip git
WORKDIR /workspace

# copy requirements
COPY requirements-build.txt /workspace/vllm/
COPY requirements-common.txt /workspace/vllm/
COPY requirements-openvino.txt /workspace/vllm/

# install build dependencies
RUN PIP_EXTRA_INDEX_URL="https://download.pytorch.org/whl/cpu" python3 -m pip install -r /workspace/vllm/requirements-build.txt
# install runtime dependencies
RUN PIP_EXTRA_INDEX_URL="https://download.pytorch.org/whl/cpu https://storage.openvinotoolkit.org/simple/wheels/nightly/" python3 -m pip install --pre -r /workspace/vllm/requirements-openvino.txt

COPY vllm/ /workspace/vllm/vllm
COPY setup.py /workspace/vllm/

# build vLLM with OpenVINO backend
RUN VLLM_TARGET_DEVICE="openvino" python3 -m pip install --no-build-isolation /workspace/vllm/

COPY examples/ /workspace/vllm/examples

CMD ["/bin/bash"]
